#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
âš¡ğŸŒŸğŸ’ ULTRA NECROZMA - CONFIGURATION CENTER ğŸ’ğŸŒŸâš¡

Central de ConfiguraÃ§Ãµes do Sistema
"The Prism that refracts all parameters into light"

Technical:  System Configuration Module
"""

from pathlib import Path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒŸ PATH CONFIGURATION (Dimensional Gates)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Input:  Raw tick data / Entrada de dados brutos
CSV_FILE = Path("/home/usuario/EURUSD_2025_COMPLETO.csv")

# Parquet:  Crystallized data / Dados cristalizados
PARQUET_FILE = Path("data/EURUSD_2025.parquet")

# Output: Analysis results / Resultados das anÃ¡lises
OUTPUT_DIR = Path("ultra_necrozma_results")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’ DATA CONFIGURATION (Crystal Structure)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# CSV columns mapping / Mapeamento de colunas CSV
CSV_COLUMNS = {
    "timestamp": "Timestamp",
    "bid": "Bid",
    "ask": "Ask",
    "symbol": "Symbol",
    "source": "Exness"
}

# Parquet compression / CompressÃ£o do Parquet
PARQUET_COMPRESSION = "snappy"  # Fast read on HDD

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš¡ ANALYSIS CONFIGURATION (Z-Crystal Parameters)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Time intervals in minutes (Temporal Dimensions)
# Technical: Resampling intervals for OHLC aggregation
INTERVALS = [1, 5, 15, 30, 60]

# Lookback periods (Dimensional Depth)
# Technical: Number of candles to analyze for patterns
LOOKBACKS = [5, 10, 15, 20, 30]

# Movement levels in pips (Energy Thresholds)
# Technical: Price movement classification thresholds
MOVEMENT_LEVELS = {
    "Pequeno": {"min": 1, "max": 5, "technical": "Small (1-5 pips)"},
    "MÃ©dio": {"min": 5, "max": 15, "technical": "Medium (5-15 pips)"},
    "Grande": {"min": 15, "max": 30, "technical": "Large (15-30 pips)"},
    "Muito Grande": {"min":  30, "max": float("inf"), "technical": "Very Large (30+ pips)"}
}

# Directions (Light Polarization)
DIRECTIONS = ["up", "down"]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ PROCESSING CONFIGURATION (Photon Burst Settings)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Parallel workers (Light Clones)
# Technical: Number of parallel processes for multiprocessing
NUM_WORKERS = 16  # Ryzen 9: 16 cores available

# Chunk size for CSV reading (Photon Packets)
# Technical: Rows per chunk during CSV import
CSV_CHUNK_SIZE = 500_000

# Minimum samples for analysis (Critical Mass)
# Technical: Minimum data points required for feature calculation
MIN_SAMPLES = 30

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒŒ FEATURE GROUPS (Prismatic Cores)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Enable/disable feature groups
# Technical: Feature extraction module toggles
FEATURE_GROUPS = {
    "derivatives": True,      # D1-D5 (Velocity, Acceleration, Jerk...)
    "spectral":  True,         # FFT, Wavelets (Frequency Domain)
    "chaos": True,            # Lyapunov, Fractal, DFA, Hurst
    "entropy": True,          # Shannon, Sample, Approximate, Permutation
    "quantum": True,          # Phase Space, Correlation Dimension
    "multifractal": True,     # Multifractal Spectrum (q-moments)
    "recurrence": True,       # RQA (Recurrence Quantification)
    "statistical": True,      # Basic statistics
    "patterns": True,         # Price patterns (crystals)
    "ultra":  True             # Photon features, Z-Crystal
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š OUTPUT CONFIGURATION (Light Crystal Formation)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Confidence thresholds (Energy Levels)
# Technical: Pattern confidence classification
CONFIDENCE_THRESHOLDS = {
    "ultra_high": 80,   # ğŸ’ Crystal Clear
    "high": 70,         # ğŸŒŸ Strong Signal
    "medium": 60,       # âš¡ Moderate Signal
    "low": 50           # âœ¨ Weak Signal
}

# Top patterns to save per level (Crystal Collection)
TOP_PATTERNS_PER_LEVEL = 50

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ® POKEMON THEME MAPPING (Ultra Necrozma Lore)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

THEME = {
    "name": "Ultra Necrozma",
    "title": "The Blinding One",
    "z_move": "Light That Burns The Sky",
    "forms": {
        "loading": "Necrozma (Prism Form)",
        "processing": "Dusk Mane / Dawn Wings",
        "analyzing": "Ultra Burst",
        "complete": "Ultra Necrozma"
    },
    "powers": {
        "dialga": "Temporal Control (Time-based analysis)",
        "palkia": "Spatial Control (Memory optimization)",
        "giratina": "Antimatter (Anomaly detection)",
        "arceus": "Divine Judgment (Final ranking)"
    },
    "crystals": {
        "Red": "Trend Power",
        "Blue": "Stability",
        "Yellow": "Volatility",
        "Green": "Balance",
        "Orange": "Momentum",
        "Violet": "Transcendence",
        "Pink": "Reversal"
    }
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ›¡ï¸ SYSTEM LIMITS (Arceus Boundaries)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Memory warning threshold in GB
MEMORY_WARNING_GB = 80

# Maximum processing time per universe in seconds
MAX_UNIVERSE_TIME = 600  # 10 minutes

# Checkpoint interval (save progress every N universes)
CHECKPOINT_INTERVAL = 5


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª TEST MODE CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Test Mode Configuration
TEST_MODE_CONFIG = {
    'strategies': {
        'minimal': {
            'weeks': 1,
            'method': 'random',
            'estimated_time_minutes': 10,
            'description': 'Smoke test - just check if it runs'
        },
        'quick': {
            'weeks': 2,
            'method': 'random',
            'estimated_time_minutes': 20,
            'description': 'Quick validation'
        },
        'balanced': {
            'weeks': 4,
            'method': 'stratified',  # 1 week per quarter
            'estimated_time_minutes': 45,
            'description': 'Balanced test with all quarters represented'
        },
        'thorough': {
            'weeks': 8,
            'method': 'diverse',  # Mix of volatility regimes
            'estimated_time_minutes': 90,
            'description': 'Thorough test before full analysis'
        }
    },
    'avoid_holidays': True,
    'default_seed': 42,
    'min_ticks_per_week': 100_000,  # Minimum ticks to consider valid week
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ HELPER FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_all_configs():
    """
    Generate all analysis configurations (Dimensional Matrix)
    Technical: Cartesian product of intervals Ã— lookbacks
    
    Returns:
        list:  List of config dictionaries
    """
    configs = []
    for interval in INTERVALS:
        for lookback in LOOKBACKS: 
            configs.append({
                "interval": interval,
                "lookback": lookback,
                "name": f"universe_{interval}m_{lookback}lb",
                "technical": f"Interval={interval}min, Lookback={lookback}periods"
            })
    return configs


def get_output_dirs():
    """
    Create and return output directory structure (Crystal Chambers)
    Technical: Initialize output folder hierarchy
    
    Returns:
        dict:  Paths to output subdirectories
    """
    dirs = {
        "root": OUTPUT_DIR,
        "universes": OUTPUT_DIR / "universes",
        "crystals": OUTPUT_DIR / "crystals", 
        "reports": OUTPUT_DIR / "reports",
        "checkpoints": OUTPUT_DIR / "checkpoints"
    }
    
    for path in dirs.values():
        path.mkdir(parents=True, exist_ok=True)
    
    return dirs


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‹ CONFIGURATION SUMMARY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__": 
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘      âš¡ğŸŒŸğŸ’ ULTRA NECROZMA CONFIGURATION ğŸ’ğŸŒŸâš¡              â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    configs = get_all_configs()
    
    print(f"ğŸ“‚ CSV Input:      {CSV_FILE}")
    print(f"ğŸ’ Parquet:        {PARQUET_FILE}")
    print(f"ğŸ“Š Output:        {OUTPUT_DIR}")
    print(f"")
    print(f"âš¡ Intervals:     {INTERVALS}")
    print(f"ğŸ”® Lookbacks:     {LOOKBACKS}")
    print(f"ğŸŒŒ Total Configs: {len(configs)}")
    print(f"")
    print(f"ğŸ”¥ Workers:       {NUM_WORKERS}")
    print(f"ğŸ’¾ Chunk Size:    {CSV_CHUNK_SIZE: ,}")
    print(f"")
    print(f"ğŸ¯ Feature Groups Enabled:")
    for group, enabled in FEATURE_GROUPS.items():
        status = "âœ…" if enabled else "âŒ"
        print(f"   {status} {group}")